{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df43f32-7949-4e7a-90be-f6797c667b83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting ujson\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f8/8c/5274ba7b4df814c87a8840a58e2b1dae6a489f49c3b0fad2d15f1e41d47b/ujson-5.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
      "Installing collected packages: ujson\n",
      "Successfully installed ujson-5.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting seaborn\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/10/5b/0479d7d845b5ba410ca702ffcd7f2cd95a14a4dfff1fde2637802b258b9b/seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (20.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ujson \n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8110a508-5c22-443e-8c2d-1f2785961a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc16b26c-4d09-4f3e-9f19-dcb81493fcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e39f6f571e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_lvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelper_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import sys \n",
    "import json \n",
    "from src import dataset_lvis\n",
    "from src import metrics\n",
    "from src import helper_functions as helper\n",
    "import importlib\n",
    "from pathlib import Path \n",
    "from PIL import Image as PILImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pandas as pd \n",
    "import time \n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "713acfd1-c1cf-44fa-b17f-bb640870fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataset_lvis' from '/home/INM705_CW_Collins_Velagala/notebooks/../src/dataset_lvis.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataset_lvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97408296-2f70-4eaa-8243-c5fdb4345c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fa061-629f-46cb-b3df-99a9c7afbcde",
   "metadata": {},
   "source": [
    "# Load train and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39685c2e-8366-47b5-9e5b-6b40e2d8c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : {1: 'armor', 2: 'horse_buggy', 3: 'cappuccino', 4: 'chessboard', 5: 'coffee_maker', 6: 'cowboy_hat', 7: 'drumstick', 8: 'monkey', 9: 'smoothie'}\n",
      "loaded 645 positive set images\n",
      "loaded 0 negative set images\n",
      "loaded 30 non-exhaustive set images\n",
      "Loaded 615 images!\n",
      "class 1 has 7 positive and 0 negative images\n",
      "class 2 has 7 positive and 0 negative images\n",
      "class 3 has 71 positive and 0 negative images\n",
      "class 4 has 9 positive and 0 negative images\n",
      "class 5 has 233 positive and 0 negative images\n",
      "class 6 has 199 positive and 0 negative images\n",
      "class 7 has 8 positive and 0 negative images\n",
      "class 8 has 73 positive and 0 negative images\n",
      "class 9 has 8 positive and 0 negative images\n",
      "1033 annotations found!\n",
      "stage:  train\n",
      "classes:  {'armor': 21, 'horse_buggy': 161, 'cappuccino': 206, 'chessboard': 240, 'coffee_maker': 284, 'cowboy_hat': 319, 'drumstick': 400, 'monkey': 699, 'smoothie': 974}\n",
      "ds_path:  ../Datasets/coco/\n",
      "labels_f:  ../Datasets/coco/annotations/lvis_v1_train.json\n",
      "imgs_dir:  ../Datasets/coco/images/train2017\n",
      "Time taken to initialize train set: 31.276674509048462\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "data_args = {'stage': 'train',\n",
    "            'classes': ['cowboy_hat', 'coffee_maker', 'monkey',\n",
    "                        'cappuccino', 'drumstick', 'chessboard',\n",
    "                        'horse_buggy', 'armor', 'smoothie'], \n",
    "            'ds_path' : \"../Datasets/coco/\",\n",
    "            'labels_dir': \"annotations\",\n",
    "            'images_dir': 'images',\n",
    "             'height' : 480,\n",
    "             'width' : 640,\n",
    "            'max_negative' : 0}\n",
    "train_data = dataset_lvis.LVISData(**data_args)\n",
    "\n",
    "print(f'Time taken to initialize train set: {time.time()-time_start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965951b-bfb1-48e8-8deb-c320b8d98b2f",
   "metadata": {},
   "source": [
    "### Split train set into custom train val set\n",
    "\n",
    "Validation set reserved for testing\n",
    "\n",
    "Check that we don't have too many of the rare cases in validation set - if so then there won't be much data to actually train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec426e15-a300-45cf-8d66-ee6dc4ffdd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 0, 3: 8, 4: 1, 5: 31, 6: 44, 7: 0, 8: 22, 9: 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what images have what classes?\n",
    "g_cpu = torch.Generator()\n",
    "g_cpu.manual_seed(3)\n",
    "\n",
    "#Split dataset to test and train\n",
    "indices = torch.randperm(len(train_data), generator=g_cpu).tolist()\n",
    "\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(train_data, indices[:550])\n",
    "dataset_val = torch.utils.data.Subset(train_data, indices[550:])\n",
    "\n",
    "\n",
    "class_counts = dict(zip(range(1,10), [0]*9))\n",
    "for _, _, y in dataset_val:\n",
    "    for label in y['labels']:\n",
    "        class_counts[label.item()] += 1\n",
    "            \n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed89f8-a249-4680-bc8a-e39015c2c63d",
   "metadata": {},
   "source": [
    "## Prepare test set\n",
    "\n",
    "The LVIS validation set is reserved for our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754ea837-6704-449b-a0b3-c5768d1b453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : {1: 'armor', 2: 'horse_buggy', 3: 'cappuccino', 4: 'chessboard', 5: 'coffee_maker', 6: 'cowboy_hat', 7: 'drumstick', 8: 'monkey', 9: 'smoothie'}\n",
      "loaded 128 positive set images\n",
      "loaded 1466 negative set images\n",
      "loaded 3 non-exhaustive set images\n",
      "Loaded 1584 images!\n",
      "class 1 has 1 positive and 189 negative images\n",
      "class 2 has 6 positive and 183 negative images\n",
      "class 3 has 17 positive and 189 negative images\n",
      "class 4 has 1 positive and 186 negative images\n",
      "class 5 has 46 positive and 172 negative images\n",
      "class 6 has 39 positive and 188 negative images\n",
      "class 7 has 2 positive and 111 negative images\n",
      "class 8 has 12 positive and 182 negative images\n",
      "class 9 has 2 positive and 123 negative images\n",
      "191 annotations found!\n",
      "stage:  val\n",
      "classes:  {'armor': 21, 'horse_buggy': 161, 'cappuccino': 206, 'chessboard': 240, 'coffee_maker': 284, 'cowboy_hat': 319, 'drumstick': 400, 'monkey': 699, 'smoothie': 974}\n",
      "ds_path:  ../Datasets/coco/\n",
      "labels_f:  ../Datasets/coco/annotations/lvis_v1_val.json\n",
      "imgs_dir:  ../Datasets/coco/images/train2017\n",
      "Time taken to initialize val set: 3.9101696014404297\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time() \n",
    "data_args = {'stage': 'val',\n",
    "            'classes': ['cowboy_hat', 'coffee_maker', 'monkey',\n",
    "                        'cappuccino', 'drumstick', 'chessboard',\n",
    "                        'horse_buggy', 'armor', 'smoothie'], \n",
    "            'ds_path' : \"../Datasets/coco/\",\n",
    "            'labels_dir': \"annotations\",\n",
    "            'images_dir': 'images',\n",
    "             'height' : 480,\n",
    "             'width' : 640,\n",
    "            'max_negative' : 200}   # note that we include negative sets for the testing\n",
    "test_data = dataset_lvis.LVISData(**data_args)\n",
    "print(f'Time taken to initialize val set: {time.time()-time_start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5210fb-ba67-46c9-a72d-2f93d89e672f",
   "metadata": {},
   "source": [
    "# Fine-tuning the model\n",
    "\n",
    "Here we set `pretrained = False` for the FPN: FPN is pre-trained on coco dataset so we'll try to retrain from scratch. We keep the backbone ResNet50 pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc402d35-ad82-4540-a29a-ed74706f7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41364461-6867-4f49-aa53-177da9f90eb2",
   "metadata": {},
   "source": [
    "# Set up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff5ce4e-729b-49b4-a1e0-28d48fc9049f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-03d3d22399a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader = torch.utils.data.DataLoader(\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#num_workers=4,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  collate_fn=helper.CollateCustom())\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m val_loader = torch.utils.data.DataLoader(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    " dataset_train, batch_size=4, shuffle=True, #num_workers=4,\n",
    " collate_fn=helper.CollateCustom())\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    " dataset_val, batch_size=4, shuffle=True, #num_workers=4,\n",
    " collate_fn=helper.CollateCustom())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af324036-b825-4573-a784-343b9dbb3a47",
   "metadata": {},
   "source": [
    "# Initialize Model + Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d139c611-3d48-4c57-8147-9fa50f2bee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has 10 classes - background and 9 specified objects\n",
    "num_classes = 10\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d532151-671e-4846-aa83-34678660c4b7",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e034c2c8-91f2-4546-84ea-b3f0085c75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after 0 epochs: 107.04226484894753\n",
      "Validation loss after 0 epochs: 10.1418876349926\n",
      "Time elapsed for 0 epochs: 90.8040497303009\n",
      "Saved checkpoint model_0_epochs.pth!\n",
      "Time elapsed after 0 epochs: 92.33182263374329\n",
      "Training loss after 1 epochs: 65.6443824917078\n",
      "Validation loss after 1 epochs: 8.879241347312927\n",
      "Time elapsed for 1 epochs: 182.31968092918396\n",
      "Training loss after 2 epochs: 52.94097135961056\n",
      "Validation loss after 2 epochs: 8.295908838510513\n",
      "Time elapsed for 2 epochs: 272.96736192703247\n",
      "Training loss after 3 epochs: 44.77424116432667\n",
      "Validation loss after 3 epochs: 8.51430270075798\n",
      "Time elapsed for 3 epochs: 364.0191922187805\n",
      "Training loss after 4 epochs: 40.07083973288536\n",
      "Validation loss after 4 epochs: 9.688126936554909\n",
      "Time elapsed for 4 epochs: 455.12225580215454\n",
      "Training loss after 5 epochs: 34.53039847314358\n",
      "Validation loss after 5 epochs: 9.768614009022713\n",
      "Time elapsed for 5 epochs: 546.3442640304565\n",
      "Saved checkpoint model_5_epochs.pth!\n",
      "Time elapsed after 5 epochs: 548.2814357280731\n",
      "Training loss after 6 epochs: 32.38795242458582\n",
      "Validation loss after 6 epochs: 10.533222988247871\n",
      "Time elapsed for 6 epochs: 639.8867161273956\n",
      "Training loss after 7 epochs: 30.109588406980038\n",
      "Validation loss after 7 epochs: 9.77363669872284\n",
      "Time elapsed for 7 epochs: 731.3570046424866\n",
      "Training loss after 8 epochs: 28.473294645547867\n",
      "Validation loss after 8 epochs: 10.412634670734406\n",
      "Time elapsed for 8 epochs: 822.9015727043152\n",
      "Training loss after 9 epochs: 28.234773628413677\n",
      "Validation loss after 9 epochs: 11.334860354661942\n",
      "Time elapsed for 9 epochs: 914.283442735672\n",
      "Training loss after 10 epochs: 26.00233045965433\n",
      "Validation loss after 10 epochs: 10.801314979791641\n",
      "Time elapsed for 10 epochs: 1005.7594900131226\n",
      "Saved checkpoint model_10_epochs.pth!\n",
      "Time elapsed after 10 epochs: 1007.2785084247589\n",
      "Training loss after 11 epochs: 25.08386678993702\n",
      "Validation loss after 11 epochs: 11.505441844463348\n",
      "Time elapsed for 11 epochs: 1098.9052934646606\n",
      "Training loss after 12 epochs: 24.415502175688744\n",
      "Validation loss after 12 epochs: 11.834502294659615\n",
      "Time elapsed for 12 epochs: 1190.4132528305054\n",
      "Training loss after 13 epochs: 23.104317776858807\n",
      "Validation loss after 13 epochs: 13.454816102981567\n",
      "Time elapsed for 13 epochs: 1281.915906906128\n",
      "Training loss after 14 epochs: 22.178292647004128\n",
      "Validation loss after 14 epochs: 13.239274442195892\n",
      "Time elapsed for 14 epochs: 1373.4071493148804\n",
      "Training loss after 15 epochs: 21.63557557016611\n",
      "Validation loss after 15 epochs: 12.700652807950974\n",
      "Time elapsed for 15 epochs: 1465.0408999919891\n",
      "Saved checkpoint model_15_epochs.pth!\n",
      "Time elapsed after 15 epochs: 1466.4934413433075\n",
      "Saved model model.pth!\n",
      "Time elapsed for 16 epochs: 24.45 min\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 16\n",
    "time_start = time.time() \n",
    "\n",
    "\n",
    "train_loss_df = pd.DataFrame(columns = ['epoch', 'loss_classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg', 'total_loss'])\n",
    "val_loss_df = pd.DataFrame(columns = ['epoch', 'loss_classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg', 'total_loss'])\n",
    "\n",
    "loss_types = ['loss_classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg', 'total_loss']\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = dict.fromkeys(loss_types, 0) \n",
    "    val_loss = dict.fromkeys(loss_types, 0) \n",
    "    \n",
    "    \"\"\"\n",
    "    Train \n",
    "    \"\"\"\n",
    "    for batch_num, (idx, X, y) in enumerate(train_loader):\n",
    "        #print(idx)\n",
    "        X = X.to(device)\n",
    "        y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "        \n",
    "        loss_dict = model(X, y) \n",
    "        \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        #save losses\n",
    "        for key in loss_types:\n",
    "            if key != 'total_loss':\n",
    "                train_loss[key] += loss_dict[key].item()\n",
    "            else: \n",
    "                train_loss['total_loss'] += losses.item()\n",
    "                \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    row = pd.DataFrame({'epoch': [epoch],\n",
    "          'loss_classifier': [train_loss['loss_classifier']/(batch_num+1)],\n",
    "          'loss_box_reg' : [train_loss['loss_box_reg']/(batch_num+1)],\n",
    "           'loss_mask': [train_loss['loss_mask']/(batch_num+1)],\n",
    "           'loss_objectness': [train_loss['loss_objectness']/(batch_num+1)],\n",
    "           'loss_rpn_box_reg': [train_loss['loss_rpn_box_reg']/(batch_num+1)],\n",
    "            'total_loss': [train_loss['total_loss']/(batch_num+1)] \n",
    "          })     \n",
    "\n",
    "    train_loss_df = pd.concat([train_loss_df, row], ignore_index = True, axis = 0)\n",
    "    \n",
    "    print(f\"Training loss after {epoch} epochs: {train_loss['total_loss']}\")\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (idx, X, y) in enumerate(val_loader):\n",
    "            X = X.to(device)\n",
    "            y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "\n",
    "            loss_dict = model(X, y) \n",
    "            \n",
    "            losses_val = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            #save losses\n",
    "            for key in loss_types:\n",
    "                if key != 'total_loss':\n",
    "                    val_loss[key] += loss_dict[key].item()\n",
    "                else: \n",
    "                    val_loss['total_loss'] += losses_val.item()\n",
    "                    \n",
    "        row = pd.DataFrame({'epoch': [epoch],\n",
    "                          'loss_classifier': [val_loss['loss_classifier']/(batch_num+1)],\n",
    "                          'loss_box_reg' : [val_loss['loss_box_reg']/(batch_num+1)],\n",
    "                           'loss_mask': [val_loss['loss_mask']/(batch_num+1)],\n",
    "                           'loss_objectness': [val_loss['loss_objectness']/(batch_num+1)],\n",
    "                           'loss_rpn_box_reg': [val_loss['loss_rpn_box_reg']/(batch_num+1)],\n",
    "                            'total_loss': [val_loss['total_loss']/(batch_num+1)] \n",
    "                          })\n",
    "        val_loss_df = pd.concat([val_loss_df, row], ignore_index = True, axis = 0)\n",
    "\n",
    "    print(f\"Validation loss after {epoch} epochs: {val_loss['total_loss']}\") \n",
    "    print(f'Time elapsed for {epoch} epochs: {time.time()-time_start}') \n",
    "\n",
    "      \n",
    "    \"\"\"\n",
    "    Save checkpoints and losses every 5 epoch\n",
    "    \"\"\"\n",
    "    if epoch%5 == 0: \n",
    "        checkpoint = {\"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                        \"step\": epoch,\n",
    "                        \"ds_args\" : data_args\n",
    "                        }\n",
    "        fname = \"model_\" + str(epoch) + \"_epochs.pth\"\n",
    "        helper.save_checkpoint(checkpoint, fname)\n",
    "        print(f'Time elapsed after {epoch} epochs: {time.time()-time_start}')  \n",
    "        val_loss_df.to_csv(Path.cwd().parent.joinpath(\"val_loss.csv\"))\n",
    "        train_loss_df.to_csv(Path.cwd().parent.joinpath(\"train_loss.csv\"))\n",
    "\n",
    "    \n",
    "    \n",
    "    #for final epoch \n",
    "    if epoch == num_epochs-1: \n",
    "        helper.save_model(model.state_dict(), \"model.pth\")\n",
    "        val_loss_df.to_csv(Path.cwd().parent.joinpath(\"val_loss.csv\"))\n",
    "        train_loss_df.to_csv(Path.cwd().parent.joinpath(\"train_loss.csv\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "print(f\"Time elapsed for {epoch+1} epochs: {round((time.time()-time_start)/60, 2)} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a9cfa-912a-4885-962c-7f7dc807ccde",
   "metadata": {},
   "source": [
    "# Plot loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f98a05-d7e5-422a-a34e-6f2a9dece363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.775669</td>\n",
       "      <td>0.596582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475684</td>\n",
       "      <td>0.522308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.38363</td>\n",
       "      <td>0.487995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.324451</td>\n",
       "      <td>0.500841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290368</td>\n",
       "      <td>0.56989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25022</td>\n",
       "      <td>0.574624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.234695</td>\n",
       "      <td>0.619601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.57492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.206328</td>\n",
       "      <td>0.612508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.666756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.188423</td>\n",
       "      <td>0.635371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.181767</td>\n",
       "      <td>0.676791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.176924</td>\n",
       "      <td>0.696147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.167423</td>\n",
       "      <td>0.79146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.160712</td>\n",
       "      <td>0.778781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.15678</td>\n",
       "      <td>0.747097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  val_loss\n",
       "0    0.775669  0.596582\n",
       "1    0.475684  0.522308\n",
       "2     0.38363  0.487995\n",
       "3    0.324451  0.500841\n",
       "4    0.290368   0.56989\n",
       "5     0.25022  0.574624\n",
       "6    0.234695  0.619601\n",
       "7    0.218185   0.57492\n",
       "8    0.206328  0.612508\n",
       "9      0.2046  0.666756\n",
       "10   0.188423  0.635371\n",
       "11   0.181767  0.676791\n",
       "12   0.176924  0.696147\n",
       "13   0.167423   0.79146\n",
       "14   0.160712  0.778781\n",
       "15    0.15678  0.747097"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = pd.DataFrame() \n",
    "#new_df['epoch'] = train_loss_df['epoch'] \n",
    "new_df['train_loss'] = train_loss_df['total_loss'] \n",
    "new_df['val_loss'] = val_loss_df['total_loss'] \n",
    "\n",
    "sns.lineplot(data = new_df[1:])\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cfaca4-1cd8-4189-bea6-512a2cf7e834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_classifier</th>\n",
       "      <th>loss_box_reg</th>\n",
       "      <th>loss_mask</th>\n",
       "      <th>loss_objectness</th>\n",
       "      <th>loss_rpn_box_reg</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.188568</td>\n",
       "      <td>0.117114</td>\n",
       "      <td>0.395325</td>\n",
       "      <td>0.056581</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.775669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.102205</td>\n",
       "      <td>0.094743</td>\n",
       "      <td>0.240977</td>\n",
       "      <td>0.023562</td>\n",
       "      <td>0.014198</td>\n",
       "      <td>0.475684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.080311</td>\n",
       "      <td>0.079507</td>\n",
       "      <td>0.201283</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.38363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.064683</td>\n",
       "      <td>0.073887</td>\n",
       "      <td>0.168909</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.00972</td>\n",
       "      <td>0.324451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.066417</td>\n",
       "      <td>0.155822</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.290368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.038415</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>0.142478</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.25022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.033892</td>\n",
       "      <td>0.055731</td>\n",
       "      <td>0.136582</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.234695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.030107</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>0.128477</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.218185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.026918</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>0.12436</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.206328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.047942</td>\n",
       "      <td>0.123756</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.021767</td>\n",
       "      <td>0.039998</td>\n",
       "      <td>0.120153</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.188423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.02021</td>\n",
       "      <td>0.039577</td>\n",
       "      <td>0.116148</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.181767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.115563</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.176924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.034032</td>\n",
       "      <td>0.111143</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.167423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>0.108528</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.160712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.031494</td>\n",
       "      <td>0.105048</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>0.15678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch loss_classifier loss_box_reg loss_mask loss_objectness  \\\n",
       "0      0        0.188568     0.117114  0.395325        0.056581   \n",
       "1      1        0.102205     0.094743  0.240977        0.023562   \n",
       "2      2        0.080311     0.079507  0.201283        0.011842   \n",
       "3      3        0.064683     0.073887  0.168909        0.007252   \n",
       "4      4        0.055323     0.066417  0.155822        0.004929   \n",
       "5      5        0.038415     0.058625  0.142478        0.002562   \n",
       "6      6        0.033892     0.055731  0.136582        0.002086   \n",
       "7      7        0.030107     0.051451  0.128477        0.001532   \n",
       "8      8        0.026918     0.047947   0.12436        0.001335   \n",
       "9      9        0.025301     0.047942  0.123756        0.001191   \n",
       "10    10        0.021767     0.039998  0.120153        0.001162   \n",
       "11    11         0.02021     0.039577  0.116148        0.000919   \n",
       "12    12        0.018244     0.038272  0.115563        0.000766   \n",
       "13    13        0.017464     0.034032  0.111143        0.000892   \n",
       "14    14        0.015502     0.031883  0.108528        0.000819   \n",
       "15    15        0.015046     0.031494  0.105048        0.000834   \n",
       "\n",
       "   loss_rpn_box_reg total_loss  \n",
       "0          0.018082   0.775669  \n",
       "1          0.014198   0.475684  \n",
       "2          0.010688    0.38363  \n",
       "3           0.00972   0.324451  \n",
       "4          0.007879   0.290368  \n",
       "5          0.008139    0.25022  \n",
       "6          0.006405   0.234695  \n",
       "7          0.006618   0.218185  \n",
       "8          0.005768   0.206328  \n",
       "9          0.006409     0.2046  \n",
       "10         0.005343   0.188423  \n",
       "11         0.004914   0.181767  \n",
       "12         0.004079   0.176924  \n",
       "13         0.003891   0.167423  \n",
       "14         0.003981   0.160712  \n",
       "15         0.004358    0.15678  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6116f24-8ab3-4546-9126-a23d4e476566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_classifier</th>\n",
       "      <th>loss_box_reg</th>\n",
       "      <th>loss_mask</th>\n",
       "      <th>loss_objectness</th>\n",
       "      <th>loss_rpn_box_reg</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.098342</td>\n",
       "      <td>0.087358</td>\n",
       "      <td>0.338142</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>0.596582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.11349</td>\n",
       "      <td>0.080512</td>\n",
       "      <td>0.281323</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.522308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.096381</td>\n",
       "      <td>0.081219</td>\n",
       "      <td>0.267518</td>\n",
       "      <td>0.02804</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.487995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.084045</td>\n",
       "      <td>0.278452</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>0.500841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.108364</td>\n",
       "      <td>0.068124</td>\n",
       "      <td>0.306936</td>\n",
       "      <td>0.048299</td>\n",
       "      <td>0.038167</td>\n",
       "      <td>0.56989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.11849</td>\n",
       "      <td>0.07378</td>\n",
       "      <td>0.314407</td>\n",
       "      <td>0.051838</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>0.574624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.130198</td>\n",
       "      <td>0.079095</td>\n",
       "      <td>0.341253</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>0.619601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.127833</td>\n",
       "      <td>0.07472</td>\n",
       "      <td>0.294363</td>\n",
       "      <td>0.061218</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.57492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.150729</td>\n",
       "      <td>0.080452</td>\n",
       "      <td>0.303348</td>\n",
       "      <td>0.061408</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.612508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.161779</td>\n",
       "      <td>0.076759</td>\n",
       "      <td>0.339255</td>\n",
       "      <td>0.07245</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.666756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.152068</td>\n",
       "      <td>0.076538</td>\n",
       "      <td>0.330197</td>\n",
       "      <td>0.060121</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.635371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.158612</td>\n",
       "      <td>0.077044</td>\n",
       "      <td>0.350008</td>\n",
       "      <td>0.074482</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.676791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.17894</td>\n",
       "      <td>0.07651</td>\n",
       "      <td>0.348048</td>\n",
       "      <td>0.077734</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.696147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.206799</td>\n",
       "      <td>0.073633</td>\n",
       "      <td>0.404339</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.014888</td>\n",
       "      <td>0.79146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.203373</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>0.399693</td>\n",
       "      <td>0.087931</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>0.778781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.192645</td>\n",
       "      <td>0.080697</td>\n",
       "      <td>0.370376</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.747097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch loss_classifier loss_box_reg loss_mask loss_objectness  \\\n",
       "0      0        0.098342     0.087358  0.338142        0.057613   \n",
       "1      1         0.11349     0.080512  0.281323        0.032731   \n",
       "2      2        0.096381     0.081219  0.267518         0.02804   \n",
       "3      3        0.095023     0.084045  0.278452        0.029158   \n",
       "4      4        0.108364     0.068124  0.306936        0.048299   \n",
       "5      5         0.11849      0.07378  0.314407        0.051838   \n",
       "6      6        0.130198     0.079095  0.341253         0.05544   \n",
       "7      7        0.127833      0.07472  0.294363        0.061218   \n",
       "8      8        0.150729     0.080452  0.303348        0.061408   \n",
       "9      9        0.161779     0.076759  0.339255         0.07245   \n",
       "10    10        0.152068     0.076538  0.330197        0.060121   \n",
       "11    11        0.158612     0.077044  0.350008        0.074482   \n",
       "12    12         0.17894      0.07651  0.348048        0.077734   \n",
       "13    13        0.206799     0.073633  0.404339          0.0918   \n",
       "14    14        0.203373     0.073693  0.399693        0.087931   \n",
       "15    15        0.192645     0.080697  0.370376        0.087275   \n",
       "\n",
       "   loss_rpn_box_reg total_loss  \n",
       "0          0.015128   0.596582  \n",
       "1          0.014253   0.522308  \n",
       "2          0.014837   0.487995  \n",
       "3          0.014163   0.500841  \n",
       "4          0.038167    0.56989  \n",
       "5          0.016109   0.574624  \n",
       "6          0.013616   0.619601  \n",
       "7          0.016786    0.57492  \n",
       "8           0.01657   0.612508  \n",
       "9          0.016513   0.666756  \n",
       "10         0.016448   0.635371  \n",
       "11         0.016644   0.676791  \n",
       "12         0.014915   0.696147  \n",
       "13         0.014888    0.79146  \n",
       "14         0.014091   0.778781  \n",
       "15         0.016104   0.747097  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e4a1c-eeec-454d-a4e1-e309680683d2",
   "metadata": {},
   "source": [
    "## Run the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "618c3906-f0c3-4bcf-88ba-6f4bdff67749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataset_lvis' from '/home/INM705_CW_Collins_Velagala/notebooks/../src/dataset_lvis.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(metrics)\n",
    "importlib.reload(dataset_lvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abe51460-a7b3-495c-9832-e7c1be7fec8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    " test_data, batch_size=1, shuffle=True, #num_workers=4,\n",
    " collate_fn=helper.CollateCustom())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e492a-4b1f-483c-bdba-04d5557f4eca",
   "metadata": {},
   "source": [
    "If testing at different time from training, then load checkpoints.\n",
    "\n",
    "Or load checkpoints from earlier stopping point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50934e2d-0ee8-4b7c-aa8a-2a49117941d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint ../model_checkpoints/model_10_epochs.pth!\n"
     ]
    }
   ],
   "source": [
    "cp_path = Path('../model_checkpoints/model_10_epochs.pth')\n",
    "helper.load_checkpoint(cp_path, model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f67b0592-6f54-43c8-a87d-094791819ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.around(np.arange(0.5, 1.0, 0.05),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c5b251e-30e4-43eb-b80e-24d4b132627e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------\n",
      "\n",
      "\n",
      "mAP for iou_threshold of 0.5: 0.196\n",
      "mAP for iou_threshold of 0.55: 0.191\n",
      "mAP for iou_threshold of 0.6: 0.188\n",
      "mAP for iou_threshold of 0.65: 0.181\n",
      "mAP for iou_threshold of 0.7: 0.155\n",
      "mAP for iou_threshold of 0.75: 0.142\n",
      "mAP for iou_threshold of 0.8: 0.119\n",
      "mAP for iou_threshold of 0.85: 0.039\n",
      "mAP for iou_threshold of 0.9: 0.020\n",
      "mAP for iou_threshold of 0.95: 0.001\n",
      "CPU times: user 5min 3s, sys: 10min 36s, total: 15min 39s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_boxes = []\n",
    "gt = []\n",
    "for idx, X, y in test_loader:\n",
    "    model.eval()\n",
    "    y_pred = model(X.to(device))\n",
    "    # keep running list of predictions and ground truths\n",
    "    pred_boxes, gt = metrics.store_preds(idx, y, y_pred,\n",
    "                                     pred_boxes, gt)\n",
    "\n",
    "mAP_list = []\n",
    "thresholds = list(np.around(np.arange(0.5, 1.0, 0.05),2))\n",
    "for iou_thresh in thresholds:\n",
    "    mAP_list.append(metrics.calculate_ap(pred_boxes, gt, \n",
    "                               iou_threshold=iou_thresh,\n",
    "                               class_datasets = test_data.class_datasets))\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    print('mAP for iou_threshold of {}: {:.3f}'.format(thresholds[i], mAP_list[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a3124-be12-4a3f-bcb5-4c0f23a0f93b",
   "metadata": {},
   "source": [
    "### Print out per category mAP\n",
    "\n",
    "Table below shows the categories we have in rows, and different IoU thresholds in columns.\n",
    "\n",
    "We also print the number of images in the test set containing each category. You can see that the model doesn't have much chance to prove itself on chessboard or drumstick categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a37a1e9d-16d8-4f6a-ba6e-877cca106e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positives</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.55</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.95</th>\n",
       "      <th>class_mAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>armor</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_buggy</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cappuccino</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chessboard</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee_maker</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.7038</td>\n",
       "      <td>0.6636</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cowboy_hat</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drumstick</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monkey</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothie</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequent_mean</th>\n",
       "      <td>42.5</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.5032</td>\n",
       "      <td>0.4457</td>\n",
       "      <td>0.3768</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.3835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common_mean</th>\n",
       "      <td>14.5</td>\n",
       "      <td>0.2369</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rare_mean</th>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               positives     0.5    0.55     0.6    0.65     0.7    0.75  \\\n",
       "armor                1.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "horse_buggy          6.0  0.0003  0.0003  0.0003  0.0003  0.0000  0.0000   \n",
       "cappuccino          17.0  0.3715  0.3715  0.3715  0.3715  0.2591  0.2591   \n",
       "chessboard           1.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "coffee_maker        46.0  0.7271  0.7271  0.7038  0.6636  0.6429  0.6210   \n",
       "cowboy_hat          39.0  0.4786  0.4786  0.4786  0.4588  0.3636  0.2705   \n",
       "drumstick            2.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "monkey              12.0  0.1023  0.0544  0.0544  0.0544  0.0466  0.0466   \n",
       "smoothie             2.0  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
       "frequent_mean       42.5  0.6028  0.6028  0.5912  0.5612  0.5032  0.4457   \n",
       "common_mean         14.5  0.2369  0.2130  0.2130  0.2130  0.1529  0.1529   \n",
       "rare_mean            2.4  0.0167  0.0167  0.0167  0.0167  0.0167  0.0167   \n",
       "\n",
       "                  0.8    0.85     0.9    0.95  class_mAP  \n",
       "armor          0.0000  0.0000  0.0000  0.0000     0.0000  \n",
       "horse_buggy    0.0000  0.0000  0.0000  0.0000     0.0001  \n",
       "cappuccino     0.2204  0.1237  0.1099  0.0000     0.2458  \n",
       "chessboard     0.0000  0.0000  0.0000  0.0000     0.0000  \n",
       "coffee_maker   0.5470  0.1787  0.0656  0.0052     0.4882  \n",
       "cowboy_hat     0.2066  0.0440  0.0089  0.0000     0.2788  \n",
       "drumstick      0.0000  0.0000  0.0000  0.0000     0.0000  \n",
       "monkey         0.0176  0.0046  0.0000  0.0000     0.0381  \n",
       "smoothie       0.0833  0.0000  0.0000  0.0000     0.0583  \n",
       "frequent_mean  0.3768  0.1113  0.0373  0.0026     0.3835  \n",
       "common_mean    0.1190  0.0642  0.0550  0.0000     0.1420  \n",
       "rare_mean      0.0167  0.0000  0.0000  0.0000     0.0117  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(index = list(range(1, 10)), columns = ['positives'] + thresholds)\n",
    "\n",
    "df['positives'] = [len(c['positive']) for c in test_data.class_datasets.values()]\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    data = [v.item() for v in mAP_list[i][1].values()]\n",
    "    df[thresholds[i]] = data\n",
    "\n",
    "df.rename(index=test_data.idx_to_classname, inplace=True)\n",
    "df.loc['frequent_mean'] = df[df.positives > 30].mean()\n",
    "df.loc['common_mean'] = df[(df.positives < 30) & (df.positives > 8)].mean()\n",
    "df.loc['rare_mean'] = df[df.positives < 8].mean()\n",
    "df['class_mAP'] = df.iloc[:, 1:].mean(axis=1)\n",
    "df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c53d6-a6df-4a2d-96ae-26e63edf2fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
