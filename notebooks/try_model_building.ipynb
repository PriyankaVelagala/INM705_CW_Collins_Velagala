{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df43f32-7949-4e7a-90be-f6797c667b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting ujson\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f8/8c/5274ba7b4df814c87a8840a58e2b1dae6a489f49c3b0fad2d15f1e41d47b/ujson-5.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
      "Installing collected packages: ujson\n",
      "Successfully installed ujson-5.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting seaborn\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/10/5b/0479d7d845b5ba410ca702ffcd7f2cd95a14a4dfff1fde2637802b258b9b/seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (20.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ujson \n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8110a508-5c22-443e-8c2d-1f2785961a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc16b26c-4d09-4f3e-9f19-dcb81493fcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import sys \n",
    "import json \n",
    "from src import dataset_lvis\n",
    "from src import metrics\n",
    "from src import helper_functions as helper\n",
    "import importlib\n",
    "from pathlib import Path \n",
    "from PIL import Image as PILImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pandas as pd \n",
    "import time \n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713acfd1-c1cf-44fa-b17f-bb640870fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataset_lvis' from '/home/INM705/INM705_CW_Collins_Velagala/notebooks/../src/dataset_lvis.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataset_lvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97408296-2f70-4eaa-8243-c5fdb4345c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fa061-629f-46cb-b3df-99a9c7afbcde",
   "metadata": {},
   "source": [
    "# Load train and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39685c2e-8366-47b5-9e5b-6b40e2d8c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : {1: 'cappuccino', 2: 'chessboard', 3: 'coffee_maker', 4: 'cowboy_hat', 5: 'drumstick', 6: 'monkey'}\n",
      "loaded 618 positive set images\n",
      "loaded 6 negative set images\n",
      "loaded 25 non-exhaustive set images\n",
      "Loaded 599 images!\n",
      "class 1 has 71 positive and 1 negative images\n",
      "class 2 has 9 positive and 1 negative images\n",
      "class 3 has 233 positive and 1 negative images\n",
      "class 4 has 199 positive and 1 negative images\n",
      "class 5 has 8 positive and 1 negative images\n",
      "class 6 has 73 positive and 1 negative images\n",
      "995 annotations found!\n",
      "stage:  train\n",
      "classes:  {'cappuccino': 206, 'chessboard': 240, 'coffee_maker': 284, 'cowboy_hat': 319, 'drumstick': 400, 'monkey': 699}\n",
      "ds_path:  /home/Datasets/coco/\n",
      "labels_f:  /home/Datasets/coco/annotations/lvis_v1_train.json\n",
      "imgs_dir:  /home/Datasets/coco/images/train2017\n",
      "Time taken to initialize train set: 39.83602046966553\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "data_args = {'stage': 'train',\n",
    "            'classes': ['cowboy_hat', 'coffee_maker', 'monkey', 'cappuccino', 'drumstick', 'chessboard'], # ['drumstick'],#'sofa'], #, 'signboard'],\n",
    "            'ds_path' : \"/home/Datasets/coco/\",\n",
    "            'labels_dir': \"annotations\",\n",
    "            'images_dir': 'images',\n",
    "             'height' : 480,\n",
    "             'width' : 640,\n",
    "            'max_negative' : 1}\n",
    "train_data = dataset_lvis.LVISData(**data_args)\n",
    "\n",
    "print(f'Time taken to initialize train set: {time.time()-time_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "754ea837-6704-449b-a0b3-c5768d1b453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : {1: 'cappuccino', 2: 'chessboard', 3: 'coffee_maker', 4: 'cowboy_hat', 5: 'drumstick', 6: 'monkey'}\n",
      "loaded 119 positive set images\n",
      "loaded 6 negative set images\n",
      "loaded 2 non-exhaustive set images\n",
      "Loaded 123 images!\n",
      "class 1 has 17 positive and 1 negative images\n",
      "class 2 has 1 positive and 1 negative images\n",
      "class 3 has 46 positive and 1 negative images\n",
      "class 4 has 39 positive and 1 negative images\n",
      "class 5 has 2 positive and 1 negative images\n",
      "class 6 has 12 positive and 1 negative images\n",
      "166 annotations found!\n",
      "stage:  val\n",
      "classes:  {'cappuccino': 206, 'chessboard': 240, 'coffee_maker': 284, 'cowboy_hat': 319, 'drumstick': 400, 'monkey': 699}\n",
      "ds_path:  /home/Datasets/coco/\n",
      "labels_f:  /home/Datasets/coco/annotations/lvis_v1_val.json\n",
      "imgs_dir:  /home/Datasets/coco/images/train2017\n",
      "Time taken to initialize val set: 3.4145913124084473\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time() \n",
    "data_args = {'stage': 'val',\n",
    "            'classes': ['cowboy_hat', 'coffee_maker', 'monkey', 'cappuccino', 'drumstick', 'chessboard'], #['drumstick'],#'sofa'], #, 'signboard'],\n",
    "            'ds_path' : \"/home/Datasets/coco/\",\n",
    "            'labels_dir': \"annotations\",\n",
    "            'images_dir': 'images',\n",
    "             'height' : 480,\n",
    "             'width' : 640,\n",
    "            'max_negative' : 1}\n",
    "val_data = dataset_lvis.LVISData(**data_args)\n",
    "print(f'Time taken to initialize val set: {time.time()-time_start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5210fb-ba67-46c9-a72d-2f93d89e672f",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc402d35-ad82-4540-a29a-ed74706f7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41364461-6867-4f49-aa53-177da9f90eb2",
   "metadata": {},
   "source": [
    "# Set up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ff5ce4e-729b-49b4-a1e0-28d48fc9049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    " train_data, batch_size=5, shuffle=True, #num_workers=4,\n",
    " collate_fn=helper.CollateCustom())\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    " val_data, batch_size=5, shuffle=True, #num_workers=4,\n",
    " collate_fn=helper.CollateCustom())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af324036-b825-4573-a784-343b9dbb3a47",
   "metadata": {},
   "source": [
    "# Initialize Model + Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d139c611-3d48-4c57-8147-9fa50f2bee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 7\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d532151-671e-4846-aa83-34678660c4b7",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e034c2c8-91f2-4546-84ea-b3f0085c75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after 0 epochs: 74.81809514760971\n",
      "Validation loss after 0 epochs: 11.418434500694275\n",
      "Time elapsed for 0 epochs: 100.04704356193542\n",
      "Saved checkpoint model_0_epochs.pth!\n",
      "Time elapsed after 0 epochs: 101.21968126296997\n",
      "Training loss after 1 epochs: 52.5003776550293\n",
      "Validation loss after 1 epochs: 10.116524681448936\n",
      "Time elapsed for 1 epochs: 202.02633929252625\n",
      "Saved model model.pth!\n",
      "Time elapsed for 2 epochs: 3.38 min\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "time_start = time.time() \n",
    "\n",
    "\n",
    "train_loss_df = pd.DataFrame(columns = ['epoch', 'loss_classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg', 'total_loss'])\n",
    "val_loss_df = pd.DataFrame(columns = ['epoch', 'loss_classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg', 'total_loss'])\n",
    "\n",
    "loss_types = ['loss_classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg', 'total_loss']\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = dict.fromkeys(loss_types, 0) \n",
    "    val_loss = dict.fromkeys(loss_types, 0) \n",
    "    \n",
    "    \"\"\"\n",
    "    Train \n",
    "    \"\"\"\n",
    "    for batch_num, (idx, X, y) in enumerate(train_loader):\n",
    "        #print(idx)\n",
    "        X = X.to(device)\n",
    "        y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "        \n",
    "        loss_dict = model(X, y) \n",
    "        \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        #save losses\n",
    "        for key in loss_types:\n",
    "            if key != 'total_loss':\n",
    "                train_loss[key] += loss_dict[key].item()\n",
    "            else: \n",
    "                train_loss['total_loss'] += losses.item()\n",
    "                \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    row = pd.DataFrame({'epoch': [epoch],\n",
    "          'loss_classifier': [train_loss['loss_classifier']/(batch_num+1)],\n",
    "          'loss_box_reg' : [train_loss['loss_box_reg']/(batch_num+1)],\n",
    "           'loss_mask': [train_loss['loss_mask']/(batch_num+1)],\n",
    "           'loss_objectness': [train_loss['loss_objectness']/(batch_num+1)],\n",
    "           'loss_rpn_box_reg': [train_loss['loss_rpn_box_reg']/(batch_num+1)],\n",
    "            'total_loss': [train_loss['total_loss']/(batch_num+1)] \n",
    "          })     \n",
    "\n",
    "    train_loss_df = pd.concat([train_loss_df, row], ignore_index = True, axis = 0)\n",
    "    \n",
    "    print(f\"Training loss after {epoch} epochs: {train_loss['total_loss']}\")\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (idx, X, y) in enumerate(val_loader):\n",
    "            X = X.to(device)\n",
    "            y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "\n",
    "            loss_dict = model(X, y) \n",
    "            \n",
    "            losses_val = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            #save losses\n",
    "            for key in loss_types:\n",
    "                if key != 'total_loss':\n",
    "                    val_loss[key] += loss_dict[key].item()\n",
    "                else: \n",
    "                    val_loss['total_loss'] += losses_val.item()\n",
    "                    \n",
    "        row = pd.DataFrame({'epoch': [epoch],\n",
    "                          'loss_classifier': [val_loss['loss_classifier']/(batch_num+1)],\n",
    "                          'loss_box_reg' : [val_loss['loss_box_reg']/(batch_num+1)],\n",
    "                           'loss_mask': [val_loss['loss_mask']/(batch_num+1)],\n",
    "                           'loss_objectness': [val_loss['loss_objectness']/(batch_num+1)],\n",
    "                           'loss_rpn_box_reg': [val_loss['loss_rpn_box_reg']/(batch_num+1)],\n",
    "                            'total_loss': [val_loss['total_loss']/(batch_num+1)] \n",
    "                          })\n",
    "        val_loss_df = pd.concat([val_loss_df, row], ignore_index = True, axis = 0)\n",
    "\n",
    "    print(f\"Validation loss after {epoch} epochs: {val_loss['total_loss']}\") \n",
    "    print(f'Time elapsed for {epoch} epochs: {time.time()-time_start}') \n",
    "\n",
    "      \n",
    "    \"\"\"\n",
    "    Save checkpoints and losses every 5 epoch\n",
    "    \"\"\"\n",
    "    if epoch%5 == 0: \n",
    "        checkpoint = {\"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                        \"step\": epoch,\n",
    "                        \"ds_args\" : data_args\n",
    "                        }\n",
    "        fname = \"model_\" + str(epoch) + \"_epochs.pth\"\n",
    "        helper.save_checkpoint(checkpoint, fname)\n",
    "        print(f'Time elapsed after {epoch} epochs: {time.time()-time_start}')  \n",
    "        val_loss_df.to_csv(Path.cwd().parent.joinpath(\"val_loss.csv\"))\n",
    "        train_loss_df.to_csv(Path.cwd().parent.joinpath(\"train_loss.csv\"))\n",
    "\n",
    "    \n",
    "    \n",
    "    #for final epoch \n",
    "    if epoch == num_epochs-1: \n",
    "        helper.save_model(model.state_dict(), \"model.pth\")\n",
    "        val_loss_df.to_csv(Path.cwd().parent.joinpath(\"val_loss.csv\"))\n",
    "        train_loss_df.to_csv(Path.cwd().parent.joinpath(\"train_loss.csv\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "print(f\"Time elapsed for {epoch+1} epochs: {round((time.time()-time_start)/60, 2)} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a9cfa-912a-4885-962c-7f7dc807ccde",
   "metadata": {},
   "source": [
    "# Plot loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96f98a05-d7e5-422a-a34e-6f2a9dece363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.623484</td>\n",
       "      <td>0.456737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.437503</td>\n",
       "      <td>0.404661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_loss  val_loss\n",
       "0   0.623484  0.456737\n",
       "1   0.437503  0.404661"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = pd.DataFrame() \n",
    "#new_df['epoch'] = train_loss_df['epoch'] \n",
    "new_df['train_loss'] = train_loss_df['total_loss'] \n",
    "new_df['val_loss'] = val_loss_df['total_loss'] \n",
    "\n",
    "sns.lineplot(data = new_df[1:])\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49cfaca4-1cd8-4189-bea6-512a2cf7e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_classifier</th>\n",
       "      <th>loss_box_reg</th>\n",
       "      <th>loss_mask</th>\n",
       "      <th>loss_objectness</th>\n",
       "      <th>loss_rpn_box_reg</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.068744</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.339946</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.04041</td>\n",
       "      <td>0.251358</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.018209</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch loss_classifier loss_box_reg loss_mask loss_objectness  \\\n",
       "0     0        0.068744     0.040985  0.339946        0.045154   \n",
       "1     1        0.049337      0.04041  0.251358        0.017429   \n",
       "\n",
       "  loss_rpn_box_reg total_loss  \n",
       "0         0.043655   0.001228  \n",
       "1         0.018209   0.000902  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6116f24-8ab3-4546-9126-a23d4e476566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_classifier</th>\n",
       "      <th>loss_box_reg</th>\n",
       "      <th>loss_mask</th>\n",
       "      <th>loss_objectness</th>\n",
       "      <th>loss_rpn_box_reg</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018872</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.131541</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01515</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.135703</td>\n",
       "      <td>0.00938</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.00018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch loss_classifier loss_box_reg loss_mask loss_objectness  \\\n",
       "0     0        0.018872     0.013484  0.131541        0.010192   \n",
       "1     1         0.01515     0.009202  0.135703         0.00938   \n",
       "\n",
       "  loss_rpn_box_reg total_loss  \n",
       "0         0.011156   0.000085  \n",
       "1         0.020077    0.00018  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e55ff-9490-4366-a193-11fff2eb5133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
